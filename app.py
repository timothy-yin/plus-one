import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import tempfile

st.set_page_config(page_title="PLUS ONE", layout="wide")
st.title("ğŸ“š PLOS ONE æœŸåˆŠä½œè€…èˆ‡æ©Ÿæ§‹æ“·å–å·¥å…·")

doi_input = st.text_area("è«‹è¼¸å…¥ DOIï¼ˆæ¯è¡Œä¸€ç­†, é™PLOS ONEæœŸåˆŠä¹‹è«–æ–‡ï¼‰")
run_button = st.button("ğŸš€ é–‹å§‹æ“·å–")

if run_button and doi_input.strip():
    dois = [d.strip() for d in doi_input.strip().split("\n")]
    all_records = []
    seen_names = set()  # ç”¨ä¾†è¨˜éŒ„å·²ç¶“å‡ºç¾éçš„ä½œè€…å§“åï¼Œé¿å…é‡è¤‡

    for doi in dois:
        xml_url = f"https://journals.plos.org/plosone/article/file?id={doi}&type=manuscript"
        response = requests.get(xml_url)

        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "lxml-xml")

            # æ–‡ç« æ¨™é¡Œ
            article_title = soup.find("article-title")
            title = article_title.get_text(strip=True) if article_title else "N/A"

            # å»ºç«‹ aff å°æ‡‰è¡¨
            aff_dict = {
                aff.get("id"): aff.find("addr-line").get_text(strip=True) if aff.find("addr-line") else aff.get_text(strip=True)
                for aff in soup.find_all("aff")
            }

            # ğŸ” åªåœ¨ <front> çš„ <contrib-group> è£¡æŠ“ä½œè€…ï¼Œé¿å…æŠ“åˆ°é™„éŒ„æˆ–åƒèˆ‡åå–®
            author_group = soup.find("contrib-group")
            authors = author_group.find_all("contrib", {"contrib-type": "author"}) if author_group else []


            for idx, author in enumerate(authors, start=1):
                surname = author.find("surname")
                given_names = author.find("given-names")
                name = f"{given_names.text.strip()} {surname.text.strip()}" if given_names and surname else surname.text.strip() if surname else "N/A"

             # é¿å…é‡è¤‡ä½œè€…å
                if name in seen_names:
                    continue
                seen_names.add(name)

                # æ¨™è¨˜ç¬¬ä¸€ä½œè€… / é€šè¨Šä½œè€…
                if idx == 1:
                   name += "ï¼ˆç¬¬ä¸€ä½œè€…ï¼‰"
                elif author.find("xref", {"ref-type": "corresp"}):
                   name += "ï¼ˆé€šè¨Šä½œè€…ï¼‰"

                # æ‰¾å°æ‡‰æ©Ÿæ§‹
                aff_ref = author.find("xref", {"ref-type": "aff"})
                aff_id = aff_ref.get("rid") if aff_ref else None
                affiliation = aff_dict.get(aff_id, "N/A")

                # å„²å­˜è³‡æ–™
                all_records.append({
                    "Order": idx,
                    "Title": title,
                    "Name": name,
                    "Affiliation": affiliation,
                    "DOI": doi
                })

        else:
            st.warning(f"âŒ ç„¡æ³•å–å¾— DOI: {doi}")

    df = pd.DataFrame(all_records)

    if df.empty:
        st.warning("âš ï¸ æ²’æœ‰æ“·å–åˆ°ä»»ä½•ä½œè€…è³‡è¨Šï¼Œè«‹æª¢æŸ¥ DOI æ˜¯å¦æ­£ç¢ºã€‚")
    else:
        st.success("âœ… æ“·å–æˆåŠŸï¼")

        # é‡æ–°è¨­å®šç´¢å¼•ï¼Œå¾ 1 é–‹å§‹
        df.index = range(1, len(df) + 1)

        # é¡¯ç¤ºè¡¨æ ¼
        st.dataframe(df, use_container_width=True)

        # æä¾› Excel ä¸‹è¼‰
        with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
            df.to_excel(tmp.name, index=True)
            st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", data=open(tmp.name, 'rb'), file_name="authors_affiliations.xlsx")
